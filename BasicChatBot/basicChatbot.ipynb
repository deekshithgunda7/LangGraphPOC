{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c93325a2",
   "metadata": {},
   "source": [
    "## Build a Basic ChatBot using LangGraph GraphAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07f79dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "059c57fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "\n",
    "    # messages have the  type lst.The add_messages function \n",
    "    # in the annotation how this state key should be updated\n",
    "    messages:Annotated[list,add_messages]\n",
    "\n",
    "graph_builder=StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840ae5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x14869d13b60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fa8e4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f309799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LLM\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "\n",
    "#initilize LLM\n",
    "llm=ChatGroq(model=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af42f68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001486A2527B0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001486A253380>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ccfd3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001486A3C8050>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001486A3C8A50>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=init_chat_model(\"groq:llama-3.1-8b-instant\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "343984e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node Functionality\n",
    "\n",
    "def chatbot(state:State):\n",
    "    return {\"messages\":[llm.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8cf488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder=StateGraph(State)\n",
    "\n",
    "#Adding Node\n",
    "graph_builder.add_node(\"llmchatbot\",chatbot)\n",
    "\n",
    "# Add Edges\n",
    "graph_builder.add_edge(START,\"llmchatbot\")\n",
    "graph_builder.add_edge(\"llmchatbot\",END)\n",
    "\n",
    "# compile the graph\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f486aef2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 400.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\deeks\\OneDrive\\Desktop\\Learning\\AI\\Langgraph\\LangGraphPOC\\.venv\\Lib\\site-packages\\IPython\\core\\formatters.py:1036\u001b[39m, in \u001b[36mMimeBundleFormatter.__call__\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n\u001b[32m   1033\u001b[39m     method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n\u001b[32m   1035\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\deeks\\OneDrive\\Desktop\\Learning\\AI\\Langgraph\\LangGraphPOC\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:758\u001b[39m, in \u001b[36mPregel._repr_mimebundle_\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_repr_mimebundle_\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    755\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Mime bundle used by Jupyter to display the graph\"\"\"\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    757\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtext/plain\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m),\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimage/png\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    759\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\deeks\\OneDrive\\Desktop\\Learning\\AI\\Langgraph\\LangGraphPOC\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\graph.py:695\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[39m\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[32m    689\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    690\u001b[39m     curve_style=curve_style,\n\u001b[32m    691\u001b[39m     node_colors=node_colors,\n\u001b[32m    692\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    693\u001b[39m     frontmatter_config=frontmatter_config,\n\u001b[32m    694\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\deeks\\OneDrive\\Desktop\\Learning\\AI\\Langgraph\\LangGraphPOC\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:294\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[39m\n\u001b[32m    288\u001b[39m     img_bytes = asyncio.run(\n\u001b[32m    289\u001b[39m         _render_mermaid_using_pyppeteer(\n\u001b[32m    290\u001b[39m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[32m    291\u001b[39m         )\n\u001b[32m    292\u001b[39m     )\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     img_bytes = \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    302\u001b[39m     supported_methods = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([m.value \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\deeks\\OneDrive\\Desktop\\Learning\\AI\\Langgraph\\LangGraphPOC\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:451\u001b[39m, in \u001b[36m_render_mermaid_using_api\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[39m\n\u001b[32m    446\u001b[39m     \u001b[38;5;66;03m# For other status codes, fail immediately\u001b[39;00m\n\u001b[32m    447\u001b[39m     msg = (\n\u001b[32m    448\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    449\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33myour graph. Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    450\u001b[39m     ) + error_msg_suffix\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (requests.RequestException, requests.Timeout) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attempt < max_retries:\n\u001b[32m    455\u001b[39m         \u001b[38;5;66;03m# Exponential backoff with jitter\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 400.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph at 0x1486a253620>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d9cd6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=graph.invoke({\"messages\":\"Hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86be9808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}, id='8319a7a5-c8e1-4752-b2ba-d7a35b80dba1'),\n",
       " AIMessage(content='How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 36, 'total_tokens': 44, 'completion_time': 0.010487327, 'prompt_time': 0.002585579, 'queue_time': 0.223421507, 'total_time': 0.013072906}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_3ddc9808b3', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--fe7c135a-647b-4b5c-8610-5352458b9334-0', usage_metadata={'input_tokens': 36, 'output_tokens': 8, 'total_tokens': 44})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79dd21ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How can I assist you today?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d65645dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just a language model, so I don't have emotions or feelings like humans do, but I'm functioning properly and ready to assist you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream({\"messages\":\"Hi , How are you ?\"}):\n",
    "    for value in event.values():\n",
    "        print(value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f315408f",
   "metadata": {},
   "source": [
    "ChatBot with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a4f3b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what is langGraph',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "   'title': 'LangGraph Tutorial: What Is LangGraph and How to Use It?',\n",
       "   'content': 'LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.',\n",
       "   'score': 0.9466806,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.analyticsvidhya.com/blog/2024/07/langgraph-revolutionizing-ai-agent/',\n",
       "   'title': 'What is LangGraph? - Analytics Vidhya',\n",
       "   'content': '* LangGraph is a library built on top of Langchain that is designed to facilitate the creation of cyclic graphs for large language model (LLM) – based AI agents. * Langgraph introduces a chat agent executor that represents the agent state as a list of messages, which is particularly useful for newer, chat-based models. The agent executor class in the Langchain framework was the main tool for building and executing AI agents before LangGraph. Large Language Models (LLMs) are the foundation for designing sophisticated AI agents, and LangGraph, built on top of Langchain, is intended to make the process of creating cyclic graphs easier. Ans. LangGraph addresses the limitations of previous AI agent development frameworks by providing more flexibility, better state management, and support for cyclic execution and multi-agent systems.',\n",
       "   'score': 0.9323611,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 1.17,\n",
       " 'request_id': 'f2d3eeee-d670-4789-ae4a-042300e388b8'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "# ans = tool.invoke(\"what is langGraph\")\n",
    "tool.invoke(\"what is langGraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b533c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'* LangGraph is a library built on top of Langchain that is designed to facilitate the creation of cyclic graphs for large language model (LLM) – based AI agents. * Langgraph introduces a chat agent executor that represents the agent state as a list of messages, which is particularly useful for newer, chat-based models. The agent executor class in the Langchain framework was the main tool for building and executing AI agents before LangGraph. Large Language Models (LLMs) are the foundation for designing sophisticated AI agents, and LangGraph, built on top of Langchain, is intended to make the process of creating cyclic graphs easier. Ans. LangGraph addresses the limitations of previous AI agent development frameworks by providing more flexibility, better state management, and support for cyclic execution and multi-agent systems.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ans[\"results\"][-1][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4cd7285",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define custom function\n",
    "\n",
    "def multiply(a:int,b:int)->int:\n",
    "\n",
    "    \"\"\"Multiply a and b\n",
    "\n",
    "    Args:\n",
    "        a (int) : first int\n",
    "        b (int) : second int\n",
    "\n",
    "    Returns:\n",
    "        int : output int   \n",
    "    \"\"\"\n",
    "\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8da6cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[tool,multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a3fac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tool=llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbbc148f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001486A3C8050>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001486A3C8A50>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'tavily_search', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. It not only retrieves URLs and snippets, but offers advanced search depths, domain management, time range filters, and image search, this tool delivers real-time, accurate, and citation-backed results.Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'Search query to look up', 'type': 'string'}, 'include_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': [], 'description': 'A list of domains to restrict search results to.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests information from specific websites (e.g., \"Find climate data from nasa.gov\")\\n        2. The user mentions an organization or company without specifying the domain (e.g., \"Find information about iPhones from Apple\")\\n\\n        In both cases, you should determine the appropriate domains (e.g., [\"nasa.gov\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will ONLY come from the specified domains - no other sources will be included.\\n        Default is None (no domain restriction).\\n        '}, 'exclude_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': [], 'description': 'A list of domains to exclude from search results.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests to avoid certain websites (e.g., \"Find information about climate change but not from twitter.com\")\\n        2. The user mentions not wanting results from specific organizations without naming the domain (e.g., \"Find phone reviews but nothing from Apple\")\\n\\n        In both cases, you should determine the appropriate domains to exclude (e.g., [\"twitter.com\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will filter out all content from the specified domains.\\n        Default is None (no domain exclusion).\\n        '}, 'search_depth': {'anyOf': [{'enum': ['basic', 'advanced'], 'type': 'string'}, {'type': 'null'}], 'default': 'basic', 'description': 'Controls search thoroughness and result comprehensiveness.\\n    \\n        Use \"basic\" for simple queries requiring quick, straightforward answers.\\n        \\n        Use \"advanced\" (default) for complex queries, specialized topics, \\n        rare information, or when in-depth analysis is needed.\\n        '}, 'include_images': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': False, 'description': 'Determines if the search returns relevant images along with text results.\\n   \\n        Set to True when the user explicitly requests visuals or when images would \\n        significantly enhance understanding (e.g., \"Show me what black holes look like,\" \\n        \"Find pictures of Renaissance art\").\\n        \\n        Leave as False (default) for most informational queries where text is sufficient.\\n        '}, 'time_range': {'anyOf': [{'enum': ['day', 'week', 'month', 'year'], 'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Limits results to content published within a specific timeframe.\\n        \\n        ONLY set this when the user explicitly mentions a time period \\n        (e.g., \"latest AI news,\" \"articles from last week\").\\n        \\n        For less popular or niche topics, use broader time ranges \\n        (\"month\" or \"year\") to ensure sufficient relevant results.\\n   \\n        Options: \"day\" (24h), \"week\" (7d), \"month\" (30d), \"year\" (365d).\\n        \\n        Default is None.\\n        '}, 'topic': {'anyOf': [{'enum': ['general', 'news', 'finance'], 'type': 'string'}, {'type': 'null'}], 'default': 'general', 'description': 'Specifies search category for optimized results.\\n   \\n        Use \"general\" (default) for most queries, INCLUDING those with terms like \\n        \"latest,\" \"newest,\" or \"recent\" when referring to general information.\\n\\n        Use \"finance\" for markets, investments, economic data, or financial news.\\n\\n        Use \"news\" ONLY for politics, sports, or major current events covered by \\n        mainstream media - NOT simply because a query asks for \"new\" information.\\n        '}, 'include_favicon': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': False, 'description': \"Determines whether to include favicon URLs for each search result.\\n        \\n        When enabled, each search result will include the website's favicon URL,\\n        which can be useful for:\\n        - Building rich UI interfaces with visual website indicators\\n        - Providing visual cues about the source's credibility or brand\\n        - Creating bookmark-like displays with recognizable site icons\\n        \\n        Set to True when creating user interfaces that benefit from visual branding\\n        or when favicon information enhances the user experience.\\n        \\n        Default is False to minimize response size and API usage.\\n        \"}, 'start_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Filters search results to include only content published on or after this date.\\n        \\n        Use this parameter when you need to:\\n        - Find recent developments or updates on a topic\\n        - Exclude outdated information from search results\\n        - Focus on content within a specific timeframe\\n        - Combine with end_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-01-15\" for January 15, 2024).\\n        \\n        Examples:\\n        - \"2024-01-01\" - Results from January 1, 2024 onwards\\n        - \"2023-12-25\" - Results from December 25, 2023 onwards\\n        \\n        When combined with end_date, creates a precise date range filter.\\n        \\n        Default is None (no start date restriction).\\n        '}, 'end_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Filters search results to include only content published on or before this date.\\n        \\n        Use this parameter when you need to:\\n        - Exclude content published after a certain date\\n        - Study historical information or past events\\n        - Research how topics were covered during specific time periods\\n        - Combine with start_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-03-31\" for March 31, 2024).\\n        \\n        Examples:\\n        - \"2024-03-31\" - Results up to and including March 31, 2024\\n        - \"2023-12-31\" - Results up to and including December 31, 2023\\n        \\n        When combined with start_date, creates a precise date range filter.\\n        For example: start_date=\"2024-01-01\", end_date=\"2024-03-31\" \\n        returns results from Q1 2024 only.\\n        \\n        Default is None (no end date restriction).\\n        '}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'multiply', 'description': 'Multiply a and b', 'parameters': {'properties': {'a': {'description': 'first int', 'type': 'integer'}, 'b': {'description': 'second int', 'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89a7272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build entire State Graph\n",
    "\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "## Node Defination\n",
    "\n",
    "def tool_calling_llm(state:State):\n",
    "    return {\"messages\":[llm_with_tool.invoke(state[\"messages\"])]}\n",
    "\n",
    "## Graph\n",
    "\n",
    "builder= StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\",tool_calling_llm)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "## Add Edge\n",
    "\n",
    "builder.add_edge(START,\"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    tools_condition\n",
    ")\n",
    "builder.add_edge(\"tools\",END)\n",
    "\n",
    "\n",
    "## Compile the graph\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "\n",
    "# from IPython.display import Image,display\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f836116",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({\"messages\":\"What is recent H1B news\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405f6f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"query\": \"H1B news\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.devdiscourse.com/article/headlines/3634541-implications-of-h-1b-visa-changes-on-south-korean-workforce\", \"title\": \"Implications of H-1B Visa Changes on South Korean Workforce - Devdiscourse\", \"score\": 0.7316155, \"published_date\": \"Sat, 20 Sep 2025 09:18:43 GMT\", \"content\": \"+ NEWS * NEWS * News # Implications of H-1B Visa Changes on South Korean Workforce ## South Korea will evaluate the effects of the U.S. H-1B visa changes on its companies and workers. The South Korean foreign ministry has announced an assessment of the recent changes to the U.S. H-1B visa program and their potential impact on South Korean enterprises and professionals aspiring to work in the United States. On Friday, the Trump administration revealed a proposal requiring companies to pay a $100,000 annual fee for each H-1B worker visa. * H-1B Visa #### US H-1B Visa Fee Surge Threatens India\\'s Tech Sector India * Technology News\", \"raw_content\": null}, {\"url\": \"https://www.business-standard.com/world-news/invest-in-us-workforce-first-nikki-haley-joins-debate-on-h1b-visa-issue-124122800069_1.html\", \"title\": \"Invest in US workforce first: Nikki Haley joins debate on H1B visa issue - Business Standard\", \"score\": 0.64478505, \"published_date\": \"Sat, 28 Dec 2024 05:33:47 GMT\", \"content\": \"Invest in US workforce first: Nikki Haley joins debate on H1B visa issue | World News - Business Standard Home / World News / Invest in US workforce first: Nikki Haley joins debate on H1B visa issue Invest in US workforce first: Nikki Haley joins debate on H1B visa issue Former South Carolina Governor, Nikki Haley has entered the debate of H1B visa allocations in the US, amid discussions by billionaire Elon Musk, Republican leader Vivek Ramaswamy, along with Sriram Krishnan--President-elect Donald Trump\\'s nominee for White House policy adviser on artificial intelligence--on expanding the visa programme. Stock Companies ListBusiness Standard at 50IPO NewsEducation NewsDelhi Elections 2024Entertainment News\", \"raw_content\": null}], \"response_time\": 0.83, \"request_id\": \"096cee6c-ae72-4eba-b04d-da6ab4430cf9\"}'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d145862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is recent H1B news\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (kpp3ryyd9)\n",
      " Call ID: kpp3ryyd9\n",
      "  Args:\n",
      "    query: H1B news\n",
      "    time_range: month\n",
      "    topic: news\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"H1B news\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.devdiscourse.com/article/headlines/3634541-implications-of-h-1b-visa-changes-on-south-korean-workforce\", \"title\": \"Implications of H-1B Visa Changes on South Korean Workforce - Devdiscourse\", \"score\": 0.7316155, \"published_date\": \"Sat, 20 Sep 2025 09:18:43 GMT\", \"content\": \"+ NEWS * NEWS * News # Implications of H-1B Visa Changes on South Korean Workforce ## South Korea will evaluate the effects of the U.S. H-1B visa changes on its companies and workers. The South Korean foreign ministry has announced an assessment of the recent changes to the U.S. H-1B visa program and their potential impact on South Korean enterprises and professionals aspiring to work in the United States. On Friday, the Trump administration revealed a proposal requiring companies to pay a $100,000 annual fee for each H-1B worker visa. * H-1B Visa #### US H-1B Visa Fee Surge Threatens India's Tech Sector India * Technology News\", \"raw_content\": null}, {\"url\": \"https://timesofindia.indiatimes.com/world/us/trumps-100000-pay-to-play-h-1b-visa-rule-sparks-outcry-immigration-attorneys-gear-up-to-file-suits/articleshow/124014488.cms\", \"title\": \"Trump’s $100,000 ‘Pay-to-Play’ H-1B visa rule sparks outcry, immigration attorneys gear up to file suits - The Times of India\", \"score\": 0.64746445, \"published_date\": \"Sat, 20 Sep 2025 10:56:00 GMT\", \"content\": \"President Donald Trump has signed a sweeping proclamation restricting the entry of H-1B visa holders unless their employers pay a supplemental $100,000 fee per worker, triggering alarm across the immigration and business community and setting the stage for immediate legal challenges.The proclamation takes effect September 21, 2025 and applies to any H-1B entering the US after 12:01am Eastern Daylight Time (EDT). GST rate cut impact: Amul lowers prices of range of items; ghee cheaper by Rs 40 - check listChina Masters: Indian badminton stars Satwiksairaj Rankireddy, Chirag Shetty sail into finalFemale cheetah explores new home at Gandhi Sagar SanctuaryWomen enetrepreneurs from Chandigarh prove their worthPunjab and Sind Bank recruitment 2025: Apply online for MMGS-II posts at punjabandsind.bank.in'Humanitarian consequences': India reacts to US H-1B visa fee hike; maps way forwardTrump H-1B Visa Hike: Why UAE, Saudi, Qatar might be better options for Indians looking to go abroadLibra, Weekly Horoscope, September 21 to September 27, 2025: Avoid big investments or risky venturesViral: Indian comedian Vir Das reacts to Trump's revised H1B visa fee\", \"raw_content\": null}], \"response_time\": 0.58, \"request_id\": \"7fbfbf39-9ca9-4013-b320-b7da386921ed\"}\n"
     ]
    }
   ],
   "source": [
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26888127",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=graph.invoke({\"messages\":\"what is 2 multiply by  3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02d1e6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is 2 multiply by  3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (c7p7j7saw)\n",
      " Call ID: c7p7j7saw\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df27636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangGraphPOC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
